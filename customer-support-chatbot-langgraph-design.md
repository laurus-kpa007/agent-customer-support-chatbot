# ê³ ê°ì§€ì› ì±—ë´‡ Agent - LangGraph PoC ìƒì„¸ ì„¤ê³„

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [PoC ë²”ìœ„ ë° ì œì•½ì‚¬í•­](#poc-ë²”ìœ„-ë°-ì œì•½ì‚¬í•­)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [ë°ì´í„° ëª¨ë¸](#ë°ì´í„°-ëª¨ë¸)
5. [LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ê³„](#langgraph-ì›Œí¬í”Œë¡œìš°-ì„¤ê³„)
6. [ì£¼ìš” ë…¸ë“œ ìƒì„¸ ì„¤ê³„](#ì£¼ìš”-ë…¸ë“œ-ìƒì„¸-ì„¤ê³„)
7. [Human-in-the-Loop êµ¬í˜„](#human-in-the-loop-êµ¬í˜„)
8. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
9. [ë””ë ‰í† ë¦¬ êµ¬ì¡°](#ë””ë ‰í† ë¦¬-êµ¬ì¡°)
10. [êµ¬í˜„ ë‹¨ê³„](#êµ¬í˜„-ë‹¨ê³„)

---

## ê°œìš”

### í”„ë¡œì íŠ¸ ëª©í‘œ
FAQì™€ Q&A ê²Œì‹œíŒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆì˜ì— ë‹¨ê³„ë³„(Step-by-Step)ë¡œ ë‹µë³€í•˜ê³ , í•´ê²°ë˜ì§€ ì•Šì„ ê²½ìš° ìë™ìœ¼ë¡œ ê²Œì‹œíŒì— ë“±ë¡í•˜ëŠ” ê³ ê°ì§€ì› ì±—ë´‡ PoC êµ¬ì¶•

### í•µì‹¬ ê¸°ëŠ¥
1. âœ… FAQ/Q&A ë°ì´í„° ë²¡í„°í™” ë° ê²€ìƒ‰
2. âœ… ë‹¨ê³„ë³„ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì œê³µ
3. âœ… Human-in-the-Loop ë°©ì‹ ëŒ€í™” ì§„í–‰
4. âœ… ë¯¸í•´ê²° ì‹œ ìë™ í‹°ì¼“ ìƒì„±
5. âœ… ë‹µë³€ ë“±ë¡ ì‹œ ì•Œë¦¼ ë°œì†¡

---

## PoC ë²”ìœ„ ë° ì œì•½ì‚¬í•­

### PoCì— í¬í•¨ë˜ëŠ” ê¸°ëŠ¥
- âœ… ë¡œì»¬ LLM ê¸°ë°˜ RAG (Ollama Gemma3 27b)
- âœ… í•œê¸€ ìµœì í™” ì„ë² ë”© (Ollama BGE-M3-Korean)
- âœ… Chroma ë²¡í„° ìŠ¤í† ì–´ (1000ê°œ FAQ ì§€ì›)
- âœ… LangGraph StateGraphë¥¼ ì´ìš©í•œ ì›Œí¬í”Œë¡œìš°
- âœ… FAQ êµ¬ì¡°í™”ëœ ë°ì´í„° (ì¦ìƒ/ì›ì¸/ì„ì‹œì¡°ì¹˜)
- âœ… ë‹¨ê³„ë³„ ë‹µë³€ ì œê³µ (ìµœëŒ€ 3ë‹¨ê³„)
- âœ… Human-in-the-Loop ì¸í„°ëŸ½íŠ¸
- âœ… ì‹¤ì‹œê°„ ì§„í–‰ ìƒíƒœ í‘œì‹œ
- âœ… **Streamlit WebUI** (ì±„íŒ… ì¸í„°í˜ì´ìŠ¤)
- âœ… ê°„ë‹¨í•œ í‹°ì¼“ ìƒì„± (JSON íŒŒì¼ ì €ì¥)
- âœ… ì´ë©”ì¼ ì•Œë¦¼ (ì½˜ì†” ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜)

### PoCì—ì„œ ì œì™¸ë˜ëŠ” ê¸°ëŠ¥
- âŒ ì‹¤ì œ ì›¹ í¬ë¡¤ë§ (1000ê°œ ìƒ˜í”Œ FAQ ë°ì´í„° ì‚¬ìš©)
- âŒ ë³µì¡í•œ GraphRAG (ê°„ë‹¨í•œ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´)
- âŒ í”„ë¡œë•ì…˜ ë°ì´í„°ë² ì´ìŠ¤ (SQLite ì‚¬ìš©)
- âŒ ì‹¤ì œ ê²Œì‹œíŒ API ì—°ë™ (Mock êµ¬í˜„)
- âŒ ì¸ì¦/ë³´ì•ˆ ê¸°ëŠ¥

### ì„±ê³µ ê¸°ì¤€
1. ì‚¬ìš©ì ì§ˆì˜ì— ëŒ€í•´ ê´€ë ¨ FAQ ê²€ìƒ‰ ì„±ê³µë¥  > 70%
2. 3ë‹¨ê³„ ì´ë‚´ ë‹¨ê³„ë³„ ë‹µë³€ ì œê³µ
3. ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€ ë° ì»¨í…ìŠ¤íŠ¸ ì´í•´
4. ë¯¸í•´ê²° ì‹œ í‹°ì¼“ ìë™ ìƒì„±
5. ì „ì²´ ì›Œí¬í”Œë¡œìš° ì •ìƒ ë™ì‘

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph UserInterface["ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"]
        WebUI[Streamlit WebUI<br/>ì±„íŒ… ì¸í„°í˜ì´ìŠ¤]
        StatusDisplay[ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ<br/>Progress Bar]
    end

    subgraph LangGraphLayer["LangGraph ì›Œí¬í”Œë¡œìš° ë ˆì´ì–´"]
        StateGraph[StateGraph<br/>ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°]

        subgraph Nodes["ë…¸ë“œë“¤"]
            InitNode[ì´ˆê¸°í™” ë…¸ë“œ<br/>initialize]
            RAGNode[RAG ê²€ìƒ‰ ë…¸ë“œ<br/>search_knowledge]
            PlanNode[ë‹µë³€ ê³„íš ë…¸ë“œ<br/>plan_response]
            RespondNode[ì‘ë‹µ ë…¸ë“œ<br/>respond_step]
            EvalNode[í‰ê°€ ë…¸ë“œ<br/>evaluate_status]
            TicketNode[í‹°ì¼“ ìƒì„± ë…¸ë“œ<br/>create_ticket]
            NotifyNode[ì•Œë¦¼ ë…¸ë“œ<br/>send_notification]
        end

        Memory[Checkpointer<br/>SqliteSaver]
        StatusUpdater[ìƒíƒœ ì—…ë°ì´íŠ¸<br/>ê° ë…¸ë“œë§ˆë‹¤]
    end

    subgraph DataLayer["ë°ì´í„° ë ˆì´ì–´"]
        VectorDB[(Vector Store<br/>Chroma)]
        TicketDB[(í‹°ì¼“ DB<br/>SQLite)]
        SampleData[1000ê°œ FAQ<br/>JSON êµ¬ì¡°í™”]
    end

    subgraph LLMLayer["ë¡œì»¬ LLM ë ˆì´ì–´"]
        LLM[Ollama<br/>Gemma3 27b]
        Embeddings[Ollama<br/>BGE-M3-Korean]
    end

    subgraph ExternalMock["ì™¸ë¶€ ì‹œìŠ¤í…œ Mock"]
        EmailMock[ì´ë©”ì¼ ë°œì†¡<br/>Console Log]
        QABoardMock[Q&A ê²Œì‹œíŒ<br/>JSON File]
    end

    WebUI --> StateGraph
    StateGraph --> Nodes
    StateGraph --> Memory
    Nodes --> StatusUpdater
    StatusUpdater --> StatusDisplay

    Nodes --> LLM
    Nodes --> Embeddings
    Nodes --> VectorDB
    Nodes --> TicketDB
    Nodes --> EmailMock
    Nodes --> QABoardMock

    SampleData --> VectorDB

    style UserInterface fill:#e1f5ff
    style LangGraphLayer fill:#e8f5e9
    style DataLayer fill:#fff3e0
    style LLMLayer fill:#fce4ec
    style ExternalMock fill:#f3e5f5
```

### LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„¸ë„

```mermaid
graph TD
    START([ì‚¬ìš©ì ì…ë ¥]) --> Initialize[ì´ˆê¸°í™”<br/>initialize]

    Initialize --> SearchKnowledge[ì§€ì‹ ê²€ìƒ‰<br/>search_knowledge<br/>Vector Search]

    SearchKnowledge --> PlanResponse[ë‹µë³€ ê³„íš<br/>plan_response<br/>ë‹¨ê³„ë³„ ë‹µë³€ ì¤€ë¹„]

    PlanResponse --> RespondStep[ë‹¨ê³„ ì‘ë‹µ<br/>respond_step<br/>í˜„ì¬ ë‹¨ê³„ ë‹µë³€]

    RespondStep --> |interrupt| HumanInput{{ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸°<br/>Human-in-the-Loop}}

    HumanInput --> EvaluateStatus[ìƒíƒœ í‰ê°€<br/>evaluate_status]

    EvaluateStatus --> |í•´ê²°ë¨| Resolved([ëŒ€í™” ì¢…ë£Œ<br/>ë¬¸ì œ í•´ê²°])

    EvaluateStatus --> |ë‹¤ìŒ ë‹¨ê³„| NextStepCheck{ë‚¨ì€ ë‹¨ê³„<br/>ìˆëŠ”ê°€?}

    NextStepCheck --> |ì˜ˆ| RespondStep
    NextStepCheck --> |ì•„ë‹ˆì˜¤| CreateTicket[í‹°ì¼“ ìƒì„±<br/>create_ticket<br/>ê²Œì‹œíŒ ë“±ë¡]

    EvaluateStatus --> |ì—ìŠ¤ì»¬ë ˆì´ì…˜| CreateTicket

    CreateTicket --> SendNotification[ì•Œë¦¼ ë°œì†¡<br/>send_notification<br/>ì´ë©”ì¼/í‘¸ì‹œ]

    SendNotification --> END([ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ])

    style START fill:#4CAF50,color:#fff
    style Initialize fill:#2196F3,color:#fff
    style SearchKnowledge fill:#FF9800,color:#fff
    style PlanResponse fill:#9C27B0,color:#fff
    style RespondStep fill:#00BCD4,color:#fff
    style HumanInput fill:#F44336,color:#fff
    style EvaluateStatus fill:#FFEB3B
    style CreateTicket fill:#E91E63,color:#fff
    style SendNotification fill:#3F51B5,color:#fff
    style Resolved fill:#4CAF50,color:#fff
    style END fill:#607D8B,color:#fff
```

---

## ë°ì´í„° ëª¨ë¸

### 1. State ê°ì²´ (TypedDict)

```python
from typing import TypedDict, List, Dict, Literal, Optional
from langchain_core.messages import BaseMessage

class SupportState(TypedDict):
    """ê³ ê°ì§€ì› ì±—ë´‡ì˜ ì „ì²´ ìƒíƒœ"""

    # ëŒ€í™” ê´€ë ¨
    messages: List[BaseMessage]              # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬
    current_query: str                       # í˜„ì¬ ì‚¬ìš©ì ì§ˆì˜

    # RAG ê²€ìƒ‰ ê²°ê³¼
    retrieved_docs: List[Dict]               # ê²€ìƒ‰ëœ FAQ ë¬¸ì„œë“¤
    relevance_score: float                   # ê´€ë ¨ì„± ì ìˆ˜

    # ë‹¨ê³„ë³„ ë‹µë³€ ê³„íš
    solution_steps: List[Dict]               # í•´ê²° ë‹¨ê³„ ëª©ë¡
    # ì˜ˆ: [
    #   {"step": 1, "action": "...", "description": "...", "completed": False},
    #   {"step": 2, "action": "...", "description": "...", "completed": False}
    # ]
    current_step: int                        # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë‹¨ê³„ (0ë¶€í„° ì‹œì‘)
    max_steps: int                           # ìµœëŒ€ ë‹¨ê³„ ìˆ˜ (ê¸°ë³¸ 3)

    # ìƒíƒœ ì¶”ì 
    status: Literal[
        "initialized",      # ì´ˆê¸°í™”ë¨
        "searching",        # ê²€ìƒ‰ ì¤‘
        "planning",         # ë‹µë³€ ê³„íš ì¤‘
        "responding",       # ì‘ë‹µ ì¤‘
        "waiting_user",     # ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸°
        "evaluating",       # í‰ê°€ ì¤‘
        "resolved",         # í•´ê²°ë¨
        "escalated",        # ì—ìŠ¤ì»¬ë ˆì´ì…˜
        "ticket_created"    # í‹°ì¼“ ìƒì„±ë¨
    ]

    # ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê´€ë ¨
    attempts: int                            # ì‹œë„ íšŸìˆ˜
    unresolved_reason: Optional[str]         # ë¯¸í•´ê²° ì‚¬ìœ 
    ticket_id: Optional[str]                 # ìƒì„±ëœ í‹°ì¼“ ID

    # ë©”íƒ€ë°ì´í„°
    user_id: str                             # ì‚¬ìš©ì ID
    session_id: str                          # ì„¸ì…˜ ID
    started_at: str                          # ì‹œì‘ ì‹œê°„
```

### 2. FAQ ë¬¸ì„œ êµ¬ì¡°

```python
class FAQSolution(TypedDict):
    """ê°œë³„ í•´ê²° ë°©ë²• êµ¬ì¡°"""
    method: int                              # ë°©ë²• ë²ˆí˜¸ (1, 2, 3, ...)
    title: str                               # ë°©ë²• ì œëª©
    steps: List[str]                         # ì‹¤í–‰ ë‹¨ê³„ë“¤
    expected_result: str                     # ê¸°ëŒ€ë˜ëŠ” ê²°ê³¼

class FAQContent(TypedDict):
    """FAQ ë³¸ë¬¸ êµ¬ì¡° (ì¦ìƒ/ì›ì¸/ì„ì‹œì¡°ì¹˜)"""
    symptom: str                             # ì¦ìƒ ì„¤ëª…
    cause: str                               # ì›ì¸ ì„¤ëª…
    solutions: List[FAQSolution]             # ì„ì‹œì¡°ì¹˜ ë°©ë²•ë“¤ (ë°©ë²•1, ë°©ë²•2, ...)

class FAQDocument(TypedDict):
    """FAQ ë¬¸ì„œ êµ¬ì¡° (1000ê°œ ê²Œì‹œê¸€ ê¸°ì¤€)"""
    id: str                                  # ë¬¸ì„œ ID (ì˜ˆ: FAQ-001)
    category: str                            # ì¹´í…Œê³ ë¦¬ (ë©”ì‹ ì €, ë¡œê·¸ì¸, ì•Œë¦¼ ë“±)
    title: str                               # ê²Œì‹œê¸€ ì œëª©
    content: FAQContent                      # ë³¸ë¬¸ (ì¦ìƒ/ì›ì¸/ì„ì‹œì¡°ì¹˜)
    tags: List[str]                          # íƒœê·¸
    created_at: str                          # ìƒì„±ì¼
    updated_at: str                          # ìˆ˜ì •ì¼
    view_count: int                          # ì¡°íšŒìˆ˜
    helpful_count: int                       # ë„ì›€ë¨ ìˆ˜
    source: Literal["faq", "qa_board"]       # ì¶œì²˜

# ì˜ˆì‹œ ë°ì´í„°
example_faq = {
    "id": "FAQ-001",
    "category": "ë©”ì‹ ì €",
    "title": "ì‹ ì°© ë©”ì‹œì§€ ì•Œë¦¼ì´ í‘œì‹œë˜ì§€ ì•ŠìŒ",
    "content": {
        "symptom": "ë©”ì‹ ì €ì—ì„œ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ë°›ì•„ë„ ì•Œë¦¼ì°½ì´ ëœ¨ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "cause": "ì•Œë¦¼ ì„¤ì •ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆê±°ë‚˜, ìš´ì˜ì²´ì œì˜ ì•Œë¦¼ ê¶Œí•œì´ ê±°ë¶€ëœ ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "solutions": [
            {
                "method": 1,
                "title": "ë©”ì‹ ì € ì•Œë¦¼ ì„¤ì • í™•ì¸",
                "steps": [
                    "í™˜ê²½ì„¤ì • ë©”ë‰´ë¥¼ ì—½ë‹ˆë‹¤",
                    "ì•Œë¦¼ íƒ­ì„ ì„ íƒí•©ë‹ˆë‹¤",
                    "'ì•Œë¦¼ì°½' ì˜µì…˜ì— ì²´í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤"
                ],
                "expected_result": "ì•Œë¦¼ì°½ì— ì²´í¬ê°€ ë˜ì–´ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
            },
            {
                "method": 2,
                "title": "ìœˆë„ìš° ì•Œë¦¼ ì„¤ì • í™•ì¸",
                "steps": [
                    "ìœˆë„ìš° ì‹œì‘ ë©”ë‰´ë¥¼ ì—½ë‹ˆë‹¤",
                    "ì„¤ì • > ì‹œìŠ¤í…œ > ì•Œë¦¼ ë° ì‘ì—…ì„ ì„ íƒí•©ë‹ˆë‹¤",
                    "'ì•± ë° ë‹¤ë¥¸ ë³´ë‚¸ ì‚¬ëŒì˜ ì•Œë¦¼ ë°›ê¸°'ë¥¼ ì¼œì§ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤"
                ],
                "expected_result": "ëª¨ë“  ì•Œë¦¼ ì„¤ì •ì´ ì¼œì§ ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤"
            },
            {
                "method": 3,
                "title": "ë©”ì‹ ì € ì¬ì‹œì‘",
                "steps": [
                    "ì‘ì—… í‘œì‹œì¤„ì—ì„œ ë©”ì‹ ì € ì•„ì´ì½˜ì„ ìš°í´ë¦­í•©ë‹ˆë‹¤",
                    "'ì¢…ë£Œ'ë¥¼ ì„ íƒí•©ë‹ˆë‹¤",
                    "ë©”ì‹ ì €ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤"
                ],
                "expected_result": "ì¬ì‹œì‘ í›„ ì•Œë¦¼ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤"
            }
        ]
    },
    "tags": ["ì•Œë¦¼", "ë©”ì‹ ì €", "ì„¤ì •"],
    "created_at": "2023-08-15",
    "updated_at": "2023-11-10",
    "view_count": 1247,
    "helpful_count": 982,
    "source": "faq"
}
```

### 3. í‹°ì¼“ êµ¬ì¡°

```python
class Ticket(TypedDict):
    """Q&A ê²Œì‹œíŒ í‹°ì¼“ êµ¬ì¡°"""
    ticket_id: str                           # í‹°ì¼“ ID
    user_id: str                             # ì‚¬ìš©ì ID
    title: str                               # ì œëª©
    content: str                             # ë‚´ìš© (ëŒ€í™” ìš”ì•½)
    conversation_history: List[Dict]         # ì „ì²´ ëŒ€í™” ë‚´ì—­
    category: str                            # ì¹´í…Œê³ ë¦¬
    status: Literal["open", "answered", "closed"]
    created_at: str                          # ìƒì„± ì‹œê°„
    answered_at: Optional[str]               # ë‹µë³€ ì‹œê°„
    answer: Optional[str]                    # ë‹µë³€ ë‚´ìš©
```

---

## LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ê³„

### StateGraph êµ¬ì¡°

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver

# ì²´í¬í¬ì¸í„° ìƒì„± (ëŒ€í™” ìƒíƒœ ì €ì¥)
memory = SqliteSaver.from_conn_string("checkpoints.db")

# StateGraph ìƒì„±
workflow = StateGraph(SupportState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("initialize", initialize_node)
workflow.add_node("search_knowledge", search_knowledge_node)
workflow.add_node("plan_response", plan_response_node)
workflow.add_node("respond_step", respond_step_node)
workflow.add_node("evaluate_status", evaluate_status_node)
workflow.add_node("create_ticket", create_ticket_node)
workflow.add_node("send_notification", send_notification_node)

# ì—£ì§€ ì •ì˜
workflow.set_entry_point("initialize")
workflow.add_edge("initialize", "search_knowledge")
workflow.add_edge("search_knowledge", "plan_response")
workflow.add_edge("plan_response", "respond_step")

# respond_step í›„ ì¸í„°ëŸ½íŠ¸ (ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸°)
workflow.add_edge("respond_step", "evaluate_status")

# ì¡°ê±´ë¶€ ë¼ìš°íŒ…
workflow.add_conditional_edges(
    "evaluate_status",
    route_next_action,  # ë¼ìš°íŒ… í•¨ìˆ˜
    {
        "continue": "respond_step",      # ë‹¤ìŒ ë‹¨ê³„ ê³„ì†
        "resolved": END,                 # í•´ê²° ì™„ë£Œ
        "escalate": "create_ticket"      # í‹°ì¼“ ìƒì„±
    }
)

workflow.add_edge("create_ticket", "send_notification")
workflow.add_edge("send_notification", END)

# ì»´íŒŒì¼
app = workflow.compile(checkpointer=memory)
```

### ë¼ìš°íŒ… ë¡œì§

```python
def route_next_action(state: SupportState) -> str:
    """ë‹¤ìŒ ì•¡ì…˜ ê²°ì •"""

    # í•´ê²°ë¨ìœ¼ë¡œ í‘œì‹œëœ ê²½ìš°
    if state["status"] == "resolved":
        return "resolved"

    # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ í‹°ì¼“ ìš”ì²­
    last_message = state["messages"][-1].content.lower()
    if any(keyword in last_message for keyword in ["ë“±ë¡í•´", "ë¬¸ì˜í•´", "í‹°ì¼“"]):
        return "escalate"

    # ëª¨ë“  ë‹¨ê³„ë¥¼ ì‹œë„í–ˆëŠ”ë°ë„ í•´ê²° ì•ˆë¨
    if state["current_step"] >= len(state["solution_steps"]):
        return "escalate"

    # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
    if state["attempts"] >= 5:
        return "escalate"

    # ë‹¤ìŒ ë‹¨ê³„ ê³„ì†
    return "continue"
```

---

## ì£¼ìš” ë…¸ë“œ ìƒì„¸ ì„¤ê³„

### 1. Initialize Node (ì´ˆê¸°í™”)

```python
from datetime import datetime
import uuid

def initialize_node(state: SupportState) -> SupportState:
    """
    ëŒ€í™” ì´ˆê¸°í™” ë…¸ë“œ
    - ì„¸ì…˜ ì •ë³´ ì„¤ì •
    - ì´ˆê¸° ìƒíƒœ ì„¤ì •
    """

    # ì²« ì‹¤í–‰ì‹œì—ë§Œ ì´ˆê¸°í™”
    if "session_id" not in state or not state["session_id"]:
        state["session_id"] = str(uuid.uuid4())
        state["started_at"] = datetime.now().isoformat()
        state["attempts"] = 0
        state["current_step"] = 0
        state["max_steps"] = 3
        state["status"] = "initialized"

    # í˜„ì¬ ì¿¼ë¦¬ ì¶”ì¶œ (ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€)
    if state["messages"]:
        last_msg = state["messages"][-1]
        if last_msg.type == "human":
            state["current_query"] = last_msg.content

    state["attempts"] += 1
    state["status"] = "searching"

    return state
```

### 2. Search Knowledge Node (ì§€ì‹ ê²€ìƒ‰)

```python
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_core.documents import Document

def search_knowledge_node(state: SupportState) -> SupportState:
    """
    RAG ê²€ìƒ‰ ë…¸ë“œ
    - ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ FAQ ê²€ìƒ‰
    - ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    """

    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    embeddings = OllamaEmbeddings(model="bge-m3-korean")
    vectorstore = Chroma(
        persist_directory="data/vectorstore",
        embedding_function=embeddings
    )

    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ)
    query = state["current_query"]
    docs_with_scores = vectorstore.similarity_search_with_score(
        query,
        k=3
    )

    # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
    retrieved_docs = []
    for doc, score in docs_with_scores:
        retrieved_docs.append({
            "id": doc.metadata.get("id", ""),
            "category": doc.metadata.get("category", ""),
            "question": doc.metadata.get("question", ""),
            "answer": doc.page_content,
            "steps": doc.metadata.get("steps", []),
            "score": float(score),
            "source": doc.metadata.get("source", "faq")
        })

    state["retrieved_docs"] = retrieved_docs

    # ìµœê³  ì ìˆ˜ ì €ì¥ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ - ì½”ì‚¬ì¸ ê±°ë¦¬)
    state["relevance_score"] = docs_with_scores[0][1] if docs_with_scores else 1.0
    state["status"] = "planning"

    return state
```

### 3. Plan Response Node (ë‹µë³€ ê³„íš)

```python
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
import json

def plan_response_node(state: SupportState) -> SupportState:
    """
    ë‹µë³€ ê³„íš ë…¸ë“œ
    - ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ê³„ë³„ í•´ê²° ë°©ë²• ìƒì„±
    - LLMì„ í™œìš©í•œ ê³„íš ìˆ˜ë¦½
    """

    llm = ChatOllama(model="gemma2:27b", temperature=0)

    # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ í¬ë§·íŒ…
    docs_context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}] (ê´€ë ¨ë„: {doc['score']:.3f})\n"
        f"ì§ˆë¬¸: {doc['question']}\n"
        f"ë‹µë³€: {doc['answer']}\n"
        f"ë‹¨ê³„: {json.dumps(doc.get('steps', []), ensure_ascii=False)}"
        for i, doc in enumerate(state["retrieved_docs"])
    ])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ê³ ê°ì§€ì› ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ:
{docs_context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "steps": [
    {{
      "step": 1,
      "action": "í™•ì¸í•  í•­ëª© ë˜ëŠ” ìˆ˜í–‰í•  ì‘ì—…",
      "description": "ìƒì„¸ ì„¤ëª…",
      "expected_result": "ê¸°ëŒ€ë˜ëŠ” ê²°ê³¼"
    }},
    ...
  ],
  "estimated_difficulty": "easy|medium|hard"
}}

ìµœëŒ€ 3ë‹¨ê³„ê¹Œì§€ë§Œ ì‘ì„±í•˜ì„¸ìš”."""),
        ("user", "ì‚¬ìš©ì ë¬¸ì œ: {query}")
    ])

    # LLM í˜¸ì¶œ
    response = llm.invoke(
        prompt.format_messages(
            docs_context=docs_context,
            query=state["current_query"]
        )
    )

    # JSON íŒŒì‹±
    try:
        plan = json.loads(response.content)
        state["solution_steps"] = plan["steps"]

        # ê° ë‹¨ê³„ì— ì™„ë£Œ ì—¬ë¶€ ì¶”ê°€
        for step in state["solution_steps"]:
            step["completed"] = False

    except json.JSONDecodeError:
        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë‹¨ê³„ ìƒì„±
        state["solution_steps"] = [{
            "step": 1,
            "action": "ê¸°ë³¸ í™•ì¸ ì‚¬í•­",
            "description": state["retrieved_docs"][0]["answer"] if state["retrieved_docs"] else "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "expected_result": "ë¬¸ì œ í•´ê²°",
            "completed": False
        }]

    state["current_step"] = 0
    state["status"] = "responding"

    return state
```

### 4. Respond Step Node (ë‹¨ê³„ë³„ ì‘ë‹µ)

```python
from langchain_core.messages import AIMessage

def respond_step_node(state: SupportState) -> SupportState:
    """
    í˜„ì¬ ë‹¨ê³„ì˜ ë‹µë³€ ì œê³µ
    - ì‚¬ìš©ìì—ê²Œ í˜„ì¬ ë‹¨ê³„ ì•ˆë‚´
    - Human-in-the-Loopì„ ìœ„í•œ ì‘ë‹µ ìƒì„±
    """

    current_idx = state["current_step"]
    steps = state["solution_steps"]

    # í˜„ì¬ ë‹¨ê³„ê°€ ì—†ìœ¼ë©´ ì—ìŠ¤ì»¬ë ˆì´ì…˜
    if current_idx >= len(steps):
        state["status"] = "escalated"
        state["unresolved_reason"] = "ëª¨ë“  ë‹¨ê³„ë¥¼ ì‹œë„í–ˆìœ¼ë‚˜ í•´ê²°ë˜ì§€ ì•ŠìŒ"

        response_text = (
            "ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë‹´ë‹¹ ë¶€ì„œì˜ í™•ì¸ì´ í•„ìš”í•œ ìƒí™©ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n"
            "í˜„ì¬ê¹Œì§€ì˜ ë¬¸ì˜ ë‚´ìš©ìœ¼ë¡œ ë¬¸ì˜ë¥¼ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
        )
    else:
        current_step = steps[current_idx]
        step_num = current_step["step"]
        total_steps = len(steps)

        response_text = (
            f"**[ë‹¨ê³„ {step_num}/{total_steps}]** {current_step['action']}\n\n"
            f"{current_step['description']}\n\n"
            f"ğŸ“Œ ê¸°ëŒ€ ê²°ê³¼: {current_step['expected_result']}\n\n"
            f"ì´ ë‹¨ê³„ë¥¼ í™•ì¸í•˜ì…¨ë‚˜ìš”? ê²°ê³¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
        )

    # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
    state["messages"].append(AIMessage(content=response_text))
    state["status"] = "waiting_user"

    return state
```

### 5. Evaluate Status Node (ìƒíƒœ í‰ê°€)

```python
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate

def evaluate_status_node(state: SupportState) -> SupportState:
    """
    ì‚¬ìš©ì ì‘ë‹µ í‰ê°€
    - ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆëŠ”ì§€ íŒë‹¨
    - ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í• ì§€ ê²°ì •
    """

    llm = ChatOllama(model="gemma2:27b", temperature=0)

    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
    last_user_message = ""
    for msg in reversed(state["messages"]):
        if msg.type == "human":
            last_user_message = msg.content
            break

    # í˜„ì¬ ë‹¨ê³„ ì •ë³´
    current_idx = state["current_step"]
    current_step = state["solution_steps"][current_idx] if current_idx < len(state["solution_steps"]) else None

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ê³ ê°ì§€ì› ëŒ€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ íŒë‹¨í•˜ì„¸ìš”:

1. "resolved": ë¬¸ì œê°€ í•´ê²°ë¨
2. "continue": í˜„ì¬ ë‹¨ê³„ê°€ íš¨ê³¼ ì—†ìŒ, ë‹¤ìŒ ë‹¨ê³„ í•„ìš”
3. "escalate": ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ë¬¸ì˜ ë“±ë¡ ìš”ì²­

íŒë‹¨ ê¸°ì¤€:
- "í•´ê²°ëì–´ìš”", "ëì–´ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤" ë“± â†’ resolved
- "ì•ˆë¼ìš”", "ì—¬ì „íˆ", "ì²´í¬ë˜ì–´ ìˆëŠ”ë°" ë“± â†’ continue
- "ë“±ë¡í•´ì£¼ì„¸ìš”", "ë¬¸ì˜í• ê²Œìš”" ë“± â†’ escalate

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{"decision": "resolved|continue|escalate", "reason": "íŒë‹¨ ì´ìœ "}}"""),
        ("user", """í˜„ì¬ ë‹¨ê³„: {current_step}
ì‚¬ìš©ì ì‘ë‹µ: {user_response}""")
    ])

    response = llm.invoke(
        prompt.format_messages(
            current_step=str(current_step),
            user_response=last_user_message
        )
    )

    try:
        evaluation = json.loads(response.content)
        decision = evaluation["decision"]

        if decision == "resolved":
            state["status"] = "resolved"
            state["messages"].append(
                AIMessage(content="ë¬¸ì œê°€ í•´ê²°ë˜ì–´ ê¸°ì©ë‹ˆë‹¤! ì¶”ê°€ë¡œ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
            )
        elif decision == "escalate":
            state["status"] = "escalated"
            state["unresolved_reason"] = evaluation["reason"]
        else:  # continue
            # í˜„ì¬ ë‹¨ê³„ë¥¼ ì™„ë£Œë¡œ í‘œì‹œí•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ
            if current_step:
                current_step["completed"] = True
            state["current_step"] += 1
            state["status"] = "responding"

    except json.JSONDecodeError:
        # ê¸°ë³¸ ë™ì‘: ë‹¤ìŒ ë‹¨ê³„ë¡œ
        state["current_step"] += 1
        state["status"] = "responding"

    return state
```

### 6. Create Ticket Node (í‹°ì¼“ ìƒì„±)

```python
import json
from datetime import datetime
import uuid

def create_ticket_node(state: SupportState) -> SupportState:
    """
    í‹°ì¼“ ìƒì„± ë…¸ë“œ
    - ëŒ€í™” ë‚´ìš© ìš”ì•½
    - Q&A ê²Œì‹œíŒì— ë“±ë¡ (PoC: JSON íŒŒì¼ ì €ì¥)
    """

    llm = ChatOllama(model="gemma2:27b", temperature=0)

    # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
    conversation = "\n".join([
        f"{'ì‚¬ìš©ì' if msg.type == 'human' else 'Agent'}: {msg.content}"
        for msg in state["messages"]
    ])

    # ìš”ì•½ ìƒì„±
    summary_prompt = ChatPromptTemplate.from_messages([
        ("system", """ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ Q&A ê²Œì‹œíŒ ì œëª©ê³¼ ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "title": "ê°„ê²°í•œ ì œëª© (20ì ì´ë‚´)",
  "summary": "ë¬¸ì œ ìƒí™© ìš”ì•½ (100ì ì´ë‚´)",
  "attempted_solutions": ["ì‹œë„í•œ í•´ê²°ë°©ë²• 1", "ì‹œë„í•œ í•´ê²°ë°©ë²• 2", ...]
}}"""),
        ("user", "ëŒ€í™” ë‚´ìš©:\n{conversation}")
    ])

    response = llm.invoke(
        summary_prompt.format_messages(conversation=conversation)
    )

    try:
        summary = json.loads(response.content)
    except json.JSONDecodeError:
        summary = {
            "title": "ê³ ê° ë¬¸ì˜",
            "summary": state["current_query"],
            "attempted_solutions": []
        }

    # í‹°ì¼“ ìƒì„±
    ticket = {
        "ticket_id": str(uuid.uuid4())[:8],
        "user_id": state.get("user_id", "anonymous"),
        "session_id": state["session_id"],
        "title": summary["title"],
        "summary": summary["summary"],
        "attempted_solutions": summary["attempted_solutions"],
        "conversation_history": [
            {"role": msg.type, "content": msg.content, "timestamp": datetime.now().isoformat()}
            for msg in state["messages"]
        ],
        "category": state["retrieved_docs"][0]["category"] if state["retrieved_docs"] else "ê¸°íƒ€",
        "status": "open",
        "created_at": datetime.now().isoformat(),
        "answered_at": None,
        "answer": None
    }

    # íŒŒì¼ë¡œ ì €ì¥ (PoC)
    ticket_file = f"data/tickets/ticket_{ticket['ticket_id']}.json"
    with open(ticket_file, "w", encoding="utf-8") as f:
        json.dump(ticket, f, ensure_ascii=False, indent=2)

    state["ticket_id"] = ticket["ticket_id"]
    state["status"] = "ticket_created"

    # ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´
    state["messages"].append(
        AIMessage(content=f"""ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ ë¬¸ì˜ë¥¼ ë“±ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.

**ë¬¸ì˜ ë²ˆí˜¸**: {ticket['ticket_id']}
**ì œëª©**: {ticket['title']}
**ìš”ì•½**: {ticket['summary']}

ë‹µë³€ì´ ë“±ë¡ë˜ë©´ ì´ë©”ì¼ë¡œ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.""")
    )

    return state
```

### 7. Send Notification Node (ì•Œë¦¼ ë°œì†¡)

```python
def send_notification_node(state: SupportState) -> SupportState:
    """
    ì•Œë¦¼ ë°œì†¡ ë…¸ë“œ
    - ì´ë©”ì¼ ì•Œë¦¼ (PoC: ì½˜ì†” ì¶œë ¥)
    - í‘¸ì‹œ ì•Œë¦¼ ì‹œë®¬ë ˆì´ì…˜
    """

    ticket_id = state.get("ticket_id", "N/A")
    user_id = state.get("user_id", "anonymous")

    # ì´ë©”ì¼ ë‚´ìš© ìƒì„±
    email_content = f"""
ì•ˆë…•í•˜ì„¸ìš”,

ë¬¸ì˜ê°€ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.

ë¬¸ì˜ë²ˆí˜¸: {ticket_id}
ë“±ë¡ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ë‹´ë‹¹ìê°€ í™•ì¸ í›„ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ë‹µë³€ì´ ë“±ë¡ë˜ë©´ ë‹¤ì‹œ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
    """

    # PoC: ì½˜ì†” ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì‹œë®¬ë ˆì´ì…˜")
    print("="*50)
    print(f"To: user_{user_id}@example.com")
    print(f"Subject: [ê³ ê°ì§€ì›] ë¬¸ì˜ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤ (#{ticket_id})")
    print(email_content)
    print("="*50 + "\n")

    # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ”:
    # send_email(
    #     to=user_email,
    #     subject=f"[ê³ ê°ì§€ì›] ë¬¸ì˜ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤ (#{ticket_id})",
    #     body=email_content
    # )

    return state
```

---

## Human-in-the-Loop êµ¬í˜„

### Interrupt ì‚¬ìš©

LangGraphëŠ” íŠ¹ì • ë…¸ë“œ ì „í›„ì— `interrupt` ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

```python
from langgraph.graph import StateGraph

# ì»´íŒŒì¼ ì‹œ interrupt ì„¤ì •
app = workflow.compile(
    checkpointer=memory,
    interrupt_before=["evaluate_status"]  # í‰ê°€ ì „ì— ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
)
```

### ì‹¤í–‰ íë¦„

```python
from langchain_core.messages import HumanMessage

# ì„¤ì •
config = {
    "configurable": {
        "thread_id": "user_session_123"  # ëŒ€í™” ìŠ¤ë ˆë“œ ID
    }
}

# 1. ì²« ì§ˆì˜
initial_input = {
    "messages": [HumanMessage(content="ë©”ì‹ ì €ì—ì„œ ì‹ ì°© ë©”ì‹œì§€ ì•Œë¦¼ì´ ì•ˆë– ìš”")],
    "user_id": "user_001"
}

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (interruptê¹Œì§€)
for event in app.stream(initial_input, config):
    print(event)

# 2. ì‚¬ìš©ì ì‘ë‹µ í›„ ì¬ê°œ
user_response = {
    "messages": [HumanMessage(content="ì²´í¬ë˜ì–´ ìˆëŠ”ë°ìš”")]
}

# ì´ì „ ìƒíƒœì—ì„œ ê³„ì†
for event in app.stream(user_response, config):
    print(event)

# 3. ê³„ì† ì§„í–‰
user_response_2 = {
    "messages": [HumanMessage(content="ê·¸ê²ƒë„ ì¼¬ìœ¼ë¡œ ë˜ì–´ ìˆì–´ìš”")]
}

for event in app.stream(user_response_2, config):
    print(event)

# 4. í‹°ì¼“ ë“±ë¡ ìš”ì²­
user_response_3 = {
    "messages": [HumanMessage(content="ë„¤ ë“±ë¡í•´ì£¼ì„¸ìš”")]
}

for event in app.stream(user_response_3, config):
    print(event)
```

### ìƒíƒœ í™•ì¸ ë° ë³µì›

```python
# í˜„ì¬ ìƒíƒœ í™•ì¸
current_state = app.get_state(config)
print(f"í˜„ì¬ ìƒíƒœ: {current_state.values['status']}")
print(f"í˜„ì¬ ë‹¨ê³„: {current_state.values['current_step']}")

# íŠ¹ì • ì‹œì ìœ¼ë¡œ ë˜ëŒë¦¬ê¸° (Time Travel)
history = app.get_state_history(config)
for state in history:
    print(f"ì‹œì : {state.config['configurable']['checkpoint_id']}")
    print(f"ìƒíƒœ: {state.values['status']}")
```

---

## ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
# requirements.txt

# LangChain ë° LangGraph
langchain==0.1.0
langchain-core==0.1.0
langchain-community==0.0.13
langgraph==0.0.20

# Ollama (ë¡œì»¬ LLM)
langchain-ollama==0.1.0
ollama==0.1.6

# ë²¡í„° ìŠ¤í† ì–´
chromadb==0.4.22

# Streamlit WebUI
streamlit==1.28.0
streamlit-chat==0.1.1

# ë°ì´í„° ì²˜ë¦¬
pandas==2.1.4
numpy==1.26.2

# ìœ í‹¸ë¦¬í‹°
python-dotenv==1.0.0
pydantic==2.5.3

# ê°œë°œ ë„êµ¬
jupyter==1.0.0
pytest==7.4.3
```

### Ollama ëª¨ë¸ ì„¤ì¹˜

```bash
# Ollama ì„¤ì¹˜ (https://ollama.ai)
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# https://ollama.ai/download ì—ì„œ ë‹¤ìš´ë¡œë“œ

# í•„ìš”í•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull gemma2:27b          # LLM ëª¨ë¸
ollama pull bge-m3-korean       # í•œê¸€ ì„ë² ë”© ëª¨ë¸ (1.2GB)

# ëª¨ë¸ í™•ì¸
ollama list
```

### í™˜ê²½ ë³€ìˆ˜ (.env)

```bash
# Ollama ì„¤ì •
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=gemma2:27b
OLLAMA_EMBEDDING_MODEL=bge-m3-korean

# ë°ì´í„° ê²½ë¡œ
DATA_DIR=./data
VECTORSTORE_PATH=./data/vectorstore
TICKETS_PATH=./data/tickets

# Streamlit ì„¤ì •
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost

# ë¡œê¹…
LOG_LEVEL=INFO
```

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
customer-support-chatbot-poc/
â”œâ”€â”€ README.md                       # í”„ë¡œì íŠ¸ ê°œìš”
â”œâ”€â”€ requirements.txt                # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env                            # í™˜ê²½ ë³€ìˆ˜
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ docs/                           # ë¬¸ì„œ
â”‚   â”œâ”€â”€ customer-support-chatbot-langgraph-design.md
â”‚   â”œâ”€â”€ microsoft-agent-framework-detailed.md
â”‚   â””â”€â”€ user-scenario-workflow.md  # ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤
â”‚
â”œâ”€â”€ data/                           # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ faq_1000.json              # 1000ê°œ FAQ ë°ì´í„°
â”‚   â”œâ”€â”€ vectorstore/               # Chroma ë²¡í„° ìŠ¤í† ì–´
â”‚   â”‚   â””â”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ tickets/                   # ìƒì„±ëœ í‹°ì¼“ë“¤
â”‚       â””â”€â”€ ticket_*.json
â”‚
â”œâ”€â”€ src/                           # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py              # State ì •ì˜
â”‚   â”‚   â”œâ”€â”€ faq.py                # FAQ ëª¨ë¸ (ì¦ìƒ/ì›ì¸/ì„ì‹œì¡°ì¹˜)
â”‚   â”‚   â””â”€â”€ ticket.py             # Ticket ëª¨ë¸
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/                     # LangGraph ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ initialize.py         # ì´ˆê¸°í™” ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ search_knowledge.py   # ê²€ìƒ‰ ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ plan_response.py      # ê³„íš ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ respond_step.py       # ì‘ë‹µ ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ evaluate_status.py    # í‰ê°€ ë…¸ë“œ
â”‚   â”‚   â”œâ”€â”€ create_ticket.py      # í‹°ì¼“ ìƒì„±
â”‚   â”‚   â””â”€â”€ send_notification.py  # ì•Œë¦¼ ë°œì†¡
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                     # ê·¸ë˜í”„ êµ¬ì„±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ workflow.py           # ì›Œí¬í”Œë¡œìš° ì •ì˜
â”‚   â”‚   â””â”€â”€ routing.py            # ë¼ìš°íŒ… ë¡œì§
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # ì„œë¹„ìŠ¤ ë ˆì´ì–´
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vectorstore.py        # Chroma ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ ollama_service.py     # Ollama LLM í˜¸ì¶œ
â”‚   â”‚   â”œâ”€â”€ ticket_service.py     # í‹°ì¼“ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ status_service.py     # ì§„í–‰ ìƒíƒœ ê´€ë¦¬
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                        # Streamlit WebUI
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                # ë©”ì¸ Streamlit ì•±
â”‚   â”‚   â”œâ”€â”€ components/           # UI ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_interface.py # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ status_display.py # ìƒíƒœ í‘œì‹œ
â”‚   â”‚   â”‚   â””â”€â”€ ticket_view.py    # í‹°ì¼“ ë·°
â”‚   â”‚   â””â”€â”€ styles.py             # CSS ìŠ¤íƒ€ì¼
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py             # ë¡œê¹… ì„¤ì •
â”‚       â””â”€â”€ config.py             # ì„¤ì • ê´€ë¦¬
â”‚
â”œâ”€â”€ scripts/                       # ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ prepare_faq_data.py       # FAQ 1000ê°œ ë°ì´í„° ì¤€ë¹„
â”‚   â”œâ”€â”€ build_vectorstore.py      # Chroma ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
â”‚   â””â”€â”€ test_ollama.py            # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_vectorstore_test.ipynb
â”‚   â””â”€â”€ 03_workflow_test.ipynb
â”‚
â”œâ”€â”€ tests/                         # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_nodes.py
â”‚   â”œâ”€â”€ test_workflow.py
â”‚   â””â”€â”€ test_integration.py
â”‚
â”œâ”€â”€ checkpoints.db                 # SQLite ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ main.py                        # CLI ì‹¤í–‰ íŒŒì¼
```

---

## êµ¬í˜„ ë‹¨ê³„

### Phase 1: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„ (1ì¼)

**Task 1.1: í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/{vectorstore,tickets}
mkdir -p src/{models,nodes,graph,services,utils}
```

**Task 1.2: ìƒ˜í”Œ ë°ì´í„° ìƒì„±**
- FAQ ë°ì´í„° 20-30ê°œ ì‘ì„± (JSON)
- Q&A ê²Œì‹œíŒ ë°ì´í„° 10-15ê°œ ì‘ì„±
- ì¹´í…Œê³ ë¦¬: ë©”ì‹ ì €, ë¡œê·¸ì¸, ì•Œë¦¼, ë„¤íŠ¸ì›Œí¬ ë“±

**Task 1.3: ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•**
```bash
python scripts/build_vectorstore.py
```

### Phase 2: ëª¨ë¸ ë° ë…¸ë“œ êµ¬í˜„ (2-3ì¼)

**Task 2.1: ë°ì´í„° ëª¨ë¸ ì •ì˜**
- `src/models/state.py` - SupportState
- `src/models/faq.py` - FAQDocument
- `src/models/ticket.py` - Ticket

**Task 2.2: ë…¸ë“œ êµ¬í˜„**
- ê° ë…¸ë“œë³„ êµ¬í˜„ (7ê°œ ë…¸ë“œ)
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**Task 2.3: ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬í˜„**
- VectorStore ê´€ë¦¬
- LLM í˜¸ì¶œ ë˜í¼
- í‹°ì¼“ CRUD

### Phase 3: ì›Œí¬í”Œë¡œìš° êµ¬ì„± (2ì¼)

**Task 3.1: StateGraph êµ¬ì„±**
- ë…¸ë“œ ì—°ê²°
- ì—£ì§€ ì •ì˜
- ë¼ìš°íŒ… ë¡œì§

**Task 3.2: Checkpointer ì„¤ì •**
- SQLite ê¸°ë°˜ ìƒíƒœ ì €ì¥
- Thread ê´€ë¦¬

### Phase 4: CLI ì¸í„°í˜ì´ìŠ¤ (1ì¼)

**Task 4.1: main.py êµ¬í˜„**
- ëŒ€í™”í˜• CLI
- ìƒíƒœ ì¶œë ¥
- ë””ë²„ê¹… ëª¨ë“œ

### Phase 5: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (1-2ì¼)

**Task 5.1: í†µí•© í…ŒìŠ¤íŠ¸**
- ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- ì—£ì§€ ì¼€ì´ìŠ¤ ê²€ì¦

**Task 5.2: ì„±ëŠ¥ ì¸¡ì •**
- ê²€ìƒ‰ ì •í™•ë„
- ì‘ë‹µ ì‹œê°„
- ì‚¬ìš©ì ê²½í—˜

### ì´ ì˜ˆìƒ ê¸°ê°„: 7-9ì¼

---

## ë‹¤ìŒ ë‹¨ê³„

ì´ ì„¤ê³„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. âœ… **ìƒ˜í”Œ ë°ì´í„° ìƒì„±**: FAQ/Q&A JSON íŒŒì¼ ì‘ì„±
2. âœ… **í”„ë¡œì íŠ¸ ìŠ¤ìºí´ë”©**: ë””ë ‰í† ë¦¬ êµ¬ì¡° ë° ê¸°ë³¸ íŒŒì¼ ìƒì„±
3. âœ… **í•µì‹¬ ë…¸ë“œ êµ¬í˜„**: 7ê°œ ë…¸ë“œ ì½”ë“œ ì‘ì„±
4. âœ… **ì›Œí¬í”Œë¡œìš° í†µí•©**: LangGraph êµ¬ì„±
5. âœ… **CLI ì‹¤í–‰**: ì‹¤ì œ ëŒ€í™” í…ŒìŠ¤íŠ¸

ì–´ë–¤ ë¶€ë¶„ë¶€í„° êµ¬í˜„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
