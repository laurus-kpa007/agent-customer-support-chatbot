"""
Test Scenario: Vague Problem â†’ Symptom Clarification â†’ Search Flow
"""

import sys
from pathlib import Path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.graph.workflow import create_workflow
from src.models.state import SupportState


def test_vague_problem_flow():
    """
    ì‹œë‚˜ë¦¬ì˜¤: ëª¨í˜¸í•œ ë¬¸ì œ ì§„ìˆ  â†’ ì¦ìƒ ì§ˆë¬¸ â†’ êµ¬ì²´ì  ë‹µë³€ â†’ ê²€ìƒ‰ â†’ í•´ê²°
    """

    print("=" * 80)
    print("ì‹œë‚˜ë¦¬ì˜¤: ëª¨í˜¸í•œ ë¬¸ì œ ì²˜ë¦¬ (ë©”ì‹ ì €ê°€ ì´ìƒí•´)")
    print("=" * 80)

    # ì›Œí¬í”Œë¡œìš° ìƒì„±
    app = create_workflow()

    # ì´ˆê¸° ìƒíƒœ
    state = SupportState(
        messages=[],
        current_query="",
        retrieved_docs=[],
        relevance_score=0.0,
        solution_steps=[],
        current_step=0,
        max_steps=3,
        status="initialized",
        attempts=0,
        unresolved_reason=None,
        ticket_id=None,
        ticket_confirmed=None,
        ticket_additional_info=None,
        intent=None,
        intent_confidence=None,
        needs_clarification=None,
        user_id="test_user_vague",
        session_id="",
        started_at="",
        debug_info=None
    )

    # === í„´ 1: ëª¨í˜¸í•œ ë¬¸ì œ ì§„ìˆ  ===
    print("\n" + "=" * 80)
    print("í„´ 1: ì‚¬ìš©ìê°€ ëª¨í˜¸í•œ ë¬¸ì œë¥¼ ì œê¸°")
    print("=" * 80)
    print("\nğŸ‘¤ ì‚¬ìš©ì: ë©”ì‹ ì €ê°€ ì´ìƒí•´")

    from langchain_core.messages import HumanMessage
    state["messages"].append(HumanMessage(content="ë©”ì‹ ì €ê°€ ì´ìƒí•´"))

    result = app.invoke(state)

    print(f"\nğŸ¤– ì‹œìŠ¤í…œ ìƒíƒœ: {result.get('status')}")
    print(f"ğŸ¤– ì˜ë„ ë¶„ë¥˜: {result.get('intent')}")
    print(f"ğŸ¤– ëª…í™•í™” í•„ìš”: {result.get('needs_clarification')}")

    # AI ì‘ë‹µ í™•ì¸
    last_ai_message = None
    for msg in reversed(result["messages"]):
        if msg.type == "ai":
            last_ai_message = msg.content
            break

    if last_ai_message:
        print(f"\nğŸ¤– ì±—ë´‡: {last_ai_message}")

    # ì¦ìƒ ì§ˆë¬¸ì„ ë°›ì•˜ëŠ”ì§€ í™•ì¸
    if result.get("needs_clarification") or "ì¦ìƒ" in last_ai_message:
        print("\nâœ… ì¦ìƒ ëª…í™•í™” ì§ˆë¬¸ì„ ì˜¬ë°”ë¥´ê²Œ ìƒì„±í–ˆìŠµë‹ˆë‹¤")
    else:
        print("\nâŒ ì¦ìƒ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤ - ë¬¸ì œ!")
        return

    # === í„´ 2: êµ¬ì²´ì ì¸ ì¦ìƒ ì œê³µ ===
    print("\n" + "=" * 80)
    print("í„´ 2: ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì¦ìƒ ì œê³µ")
    print("=" * 80)
    print("\nğŸ‘¤ ì‚¬ìš©ì: ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë ¤ê³  í•˜ë©´ 'ì „ì†¡ ì‹¤íŒ¨' ì˜¤ë¥˜ê°€ ë‚˜ìš”")

    result["messages"].append(HumanMessage(content="ë©”ì‹œì§€ë¥¼ ë³´ë‚´ë ¤ê³  í•˜ë©´ 'ì „ì†¡ ì‹¤íŒ¨' ì˜¤ë¥˜ê°€ ë‚˜ìš”"))

    result = app.invoke(result)

    print(f"\nğŸ¤– ì‹œìŠ¤í…œ ìƒíƒœ: {result.get('status')}")
    print(f"ğŸ¤– í˜„ì¬ ì¿¼ë¦¬: {result.get('current_query')}")
    print(f"ğŸ¤– ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(result.get('retrieved_docs', []))}")

    # AI ì‘ë‹µ í™•ì¸
    last_ai_message = None
    for msg in reversed(result["messages"]):
        if msg.type == "ai":
            last_ai_message = msg.content
            break

    if last_ai_message:
        print(f"\nğŸ¤– ì±—ë´‡: {last_ai_message[:200]}...")

    # ê²€ìƒ‰ì´ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if result.get("retrieved_docs") and len(result.get("retrieved_docs", [])) > 0:
        print("\nâœ… êµ¬ì²´ì ì¸ ì¦ìƒìœ¼ë¡œ ê²€ìƒ‰ì„ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤")
        print(f"   - ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_docs'])}")
        print(f"   - í•´ê²° ë‹¨ê³„ ìˆ˜: {len(result.get('solution_steps', []))}")
    else:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")

    # === í„´ 3: ë‹¨ê³„ ìˆ˜í–‰ ===
    print("\n" + "=" * 80)
    print("í„´ 3: ì²« ë²ˆì§¸ ë‹¨ê³„ ìˆ˜í–‰")
    print("=" * 80)
    print("\nğŸ‘¤ ì‚¬ìš©ì: ë„¤íŠ¸ì›Œí¬ ì„¤ì • í™•ì¸í–ˆì–´ìš”")

    result["messages"].append(HumanMessage(content="ë„¤íŠ¸ì›Œí¬ ì„¤ì • í™•ì¸í–ˆì–´ìš”"))

    result = app.invoke(result)

    print(f"\nğŸ¤– ì‹œìŠ¤í…œ ìƒíƒœ: {result.get('status')}")
    print(f"ğŸ¤– í˜„ì¬ ë‹¨ê³„: {result.get('current_step')}")

    # AI ì‘ë‹µ í™•ì¸
    last_ai_message = None
    for msg in reversed(result["messages"]):
        if msg.type == "ai":
            last_ai_message = msg.content
            break

    if last_ai_message:
        print(f"\nğŸ¤– ì±—ë´‡: {last_ai_message[:200]}...")

    # "í–ˆì–´ìš”"ê°€ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸ (continueë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨)
    if result.get("status") == "waiting_user" and result.get("current_step") > 0:
        print("\nâœ… 'í–ˆì–´ìš”' í‘œí˜„ì„ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤ (ë‹¤ìŒ ë‹¨ê³„ ì œì‹œ)")
    elif result.get("status") == "resolved":
        print("\nâŒ 'í–ˆì–´ìš”'ë¥¼ í•´ê²°ë¡œ ì˜ëª» ì¸ì‹í–ˆìŠµë‹ˆë‹¤!")

    # === í„´ 4: í•´ê²° í™•ì¸ ===
    print("\n" + "=" * 80)
    print("í„´ 4: ë¬¸ì œ í•´ê²°")
    print("=" * 80)
    print("\nğŸ‘¤ ì‚¬ìš©ì: ì´ì œ ë©”ì‹œì§€ ì „ì†¡ì´ ì˜ ë¼ìš”!")

    result["messages"].append(HumanMessage(content="ì´ì œ ë©”ì‹œì§€ ì „ì†¡ì´ ì˜ ë¼ìš”!"))

    result = app.invoke(result)

    print(f"\nğŸ¤– ì‹œìŠ¤í…œ ìƒíƒœ: {result.get('status')}")

    # AI ì‘ë‹µ í™•ì¸
    last_ai_message = None
    for msg in reversed(result["messages"]):
        if msg.type == "ai":
            last_ai_message = msg.content
            break

    if last_ai_message:
        print(f"\nğŸ¤– ì±—ë´‡: {last_ai_message}")

    if result.get("status") == "resolved":
        print("\nâœ… ë¬¸ì œ í•´ê²°ì„ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í–ˆìŠµë‹ˆë‹¤")
    else:
        print(f"\nâŒ í•´ê²° ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: {result.get('status')}")

    print("\n" + "=" * 80)
    print("ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ")
    print("=" * 80)


if __name__ == "__main__":
    test_vague_problem_flow()
