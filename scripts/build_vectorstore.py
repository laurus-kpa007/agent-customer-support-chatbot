#!/usr/bin/env python3
"""ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸

FAQ JSON íŒŒì¼ì„ ì½ì–´ì„œ Chroma ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
ë¬¸ì„œ ì „ì²´ ì²­í‚¹ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ í•´ê²° ë°©ë²•ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
"""

import json
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def load_faq_data(file_path: str) -> list:
    """FAQ JSON íŒŒì¼ ë¡œë“œ"""
    print(f"ğŸ“š FAQ ë°ì´í„° ë¡œë“œ ì¤‘... ({file_path})")

    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"âœ… {len(data)}ê°œ FAQ ë¡œë“œ ì™„ë£Œ")
    return data


def create_documents_from_faq(faq_data: list) -> list:
    """FAQ ë°ì´í„°ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜ (ì „ì²´ ë¬¸ì„œ ì²­í‚¹)

    ì²­í‚¹ ì „ëµ: ê° FAQ ë¬¸ì„œë¥¼ í†µì§¸ë¡œ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì²˜ë¦¬
    - ì¥ì : í•´ê²° ë°©ë²•ì´ ì ˆëŒ€ ì˜ë¦¬ì§€ ì•ŠìŒ
    - ì í•©ì„±: FAQ í¬ê¸°ê°€ 1000-2000ìë¡œ ì ë‹¹í•¨
    """
    print("\nğŸ“„ Document ê°ì²´ ìƒì„± ì¤‘...")
    documents = []

    for faq in faq_data:
        # ì „ì²´ FAQ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ êµ¬ì„±
        content = f"""ì œëª©: {faq['title']}
ì¹´í…Œê³ ë¦¬: {faq['category']}

ì¦ìƒ:
{faq['content']['symptom']}

ì›ì¸:
{faq['content']['cause']}

í•´ê²° ë°©ë²•:
"""
        # ëª¨ë“  í•´ê²° ë°©ë²•ì„ ì™„ì „í•˜ê²Œ í¬í•¨
        for solution in faq['content']['solutions']:
            content += f"\n[ë°©ë²• {solution['method']}] {solution['title']}\n"
            for i, step in enumerate(solution['steps'], 1):
                content += f"  {i}. {step}\n"
            content += f"  â–¶ ê¸°ëŒ€ ê²°ê³¼: {solution['expected_result']}\n"

        # Document ìƒì„± (ë©”íƒ€ë°ì´í„° í¬í•¨)
        doc = Document(
            page_content=content,
            metadata={
                "id": faq["id"],
                "category": faq["category"],
                "title": faq["title"],
                "tags": faq["tags"],
                "source": faq["source"],
                "helpful_count": faq["helpful_count"],
                "created_at": faq["created_at"]
            }
        )
        documents.append(doc)

    print(f"âœ… {len(documents)}ê°œ Document ìƒì„± ì™„ë£Œ")
    print(f"   - í‰ê·  ê¸¸ì´: {sum(len(d.page_content) for d in documents) // len(documents)}ì")
    print(f"   - ìµœëŒ€ ê¸¸ì´: {max(len(d.page_content) for d in documents)}ì")
    print(f"   - ìµœì†Œ ê¸¸ì´: {min(len(d.page_content) for d in documents)}ì")

    return documents


def build_vectorstore(documents: list, persist_directory: str = "data/vectorstore") -> Chroma:
    """Chroma ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•"""

    # Ollama ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print("\nğŸ”„ Ollama ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
    embedding_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "bge-m3-korean")
    print(f"   - ëª¨ë¸: {embedding_model}")

    try:
        embeddings = OllamaEmbeddings(model=embedding_model)
        print("âœ… BGE-M3-Korean ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("   ollama serve")
        print(f"\nğŸ’¡ ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print(f"   ollama pull {embedding_model}")
        sys.exit(1)

    # Chroma ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
    print(f"\nğŸ—„ï¸  Chroma ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì¤‘...")
    print(f"   - ì €ì¥ ê²½ë¡œ: {persist_directory}")
    print(f"   - ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ")
    print(f"   - ì„ë² ë”© ì§„í–‰ ì¤‘... (ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

    try:
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=embeddings,
            persist_directory=persist_directory,
            collection_name="faq_collection"
        )
        print("âœ… ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        sys.exit(1)

    return vectorstore


def test_search(vectorstore: Chroma):
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")

    test_queries = [
        "ë©”ì‹ ì €ì—ì„œ ì•Œë¦¼ì´ ì•ˆë– ìš”",
        "ë¹„ë°€ë²ˆí˜¸ë¥¼ ìŠì–´ë²„ë ¸ì–´ìš”",
        "íŒŒì¼ ì—…ë¡œë“œê°€ ì•ˆë¼ìš”"
    ]

    for query in test_queries:
        print(f"\nğŸ“Œ ì¿¼ë¦¬: {query}")
        results = vectorstore.similarity_search(query, k=2)

        for i, doc in enumerate(results, 1):
            print(f"\n   [{i}] {doc.metadata['title']}")
            print(f"       ì¹´í…Œê³ ë¦¬: {doc.metadata['category']}")
            print(f"       ID: {doc.metadata['id']}")
            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 100ì)
            preview = doc.page_content.replace('\n', ' ')[:100]
            print(f"       ë‚´ìš©: {preview}...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("  FAQ ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸")
    print("  - ì „ëµ: ë¬¸ì„œ ì „ì²´ ì²­í‚¹ (í•´ê²° ë°©ë²• ì™„ì „ ë³´ì¡´)")
    print("  - ë²¡í„° DB: Chroma")
    print("  - ì„ë² ë”©: Ollama BGE-M3-Korean")
    print("="*60)

    # FAQ ë°ì´í„° ë¡œë“œ
    faq_file = "data/faq_sample.json"
    if not os.path.exists(faq_file):
        print(f"âŒ FAQ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {faq_file}")
        sys.exit(1)

    faq_data = load_faq_data(faq_file)

    # Document ê°ì²´ ìƒì„±
    documents = create_documents_from_faq(faq_data)

    # ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
    vectorstore = build_vectorstore(documents)

    # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
    test_search(vectorstore)

    print("\n" + "="*60)
    print("âœ… ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ!")
    print("="*60)
    print(f"\nì €ì¥ ìœ„ì¹˜: {os.path.abspath('data/vectorstore')}")
    print("\nì´ì œ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("  streamlit run src/ui/app.py")


if __name__ == "__main__":
    main()
