#!/usr/bin/env python3
"""Chroma ë²¡í„° ìŠ¤í† ì–´ ë°ì´í„° í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv

load_dotenv()


def inspect_vectorstore(persist_directory: str = "data/vectorstore"):
    """ë²¡í„° ìŠ¤í† ì–´ ë‚´ìš© í™•ì¸"""

    print("="*60)
    print("  Chroma ë²¡í„° ìŠ¤í† ì–´ ë°ì´í„° í™•ì¸")
    print("="*60)

    if not os.path.exists(persist_directory):
        print(f"\nâŒ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persist_directory}")
        print("\në¨¼ì € ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”:")
        print("  python scripts/build_vectorstore.py")
        sys.exit(1)

    print(f"\nğŸ“‚ ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ: {os.path.abspath(persist_directory)}")

    # Ollama ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "bge-m3-korean")
    embeddings = OllamaEmbeddings(model=embedding_model)

    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    print(f"\nğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    vectorstore = Chroma(
        persist_directory=persist_directory,
        embedding_function=embeddings,
        collection_name="faq_collection"
    )

    # ì»¬ë ‰ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    collection = vectorstore._collection

    print("\n" + "="*60)
    print("ğŸ“Š ë²¡í„° ìŠ¤í† ì–´ í†µê³„")
    print("="*60)
    print(f"ì´ ë¬¸ì„œ ìˆ˜: {collection.count()}")

    # ì „ì²´ ë°ì´í„° ì¡°íšŒ (ìµœëŒ€ 100ê°œ)
    results = collection.get(
        include=['metadatas', 'documents'],
        limit=100
    )

    print(f"\nğŸ“‹ ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ (ìµœëŒ€ 100ê°œ):")
    print("-"*60)

    if results['ids']:
        for i, (doc_id, metadata, document) in enumerate(zip(
            results['ids'],
            results['metadatas'],
            results['documents']
        ), 1):
            print(f"\n[{i}] ID: {doc_id}")
            print(f"    ì œëª©: {metadata.get('title', 'N/A')}")
            print(f"    ì¹´í…Œê³ ë¦¬: {metadata.get('category', 'N/A')}")
            print(f"    íƒœê·¸: {metadata.get('tags', 'N/A')}")
            print(f"    ë„ì›€ë¨: {metadata.get('helpful_count', 0)}íšŒ")
            print(f"    ìƒì„±ì¼: {metadata.get('created_at', 'N/A')}")
            print(f"    ë¬¸ì„œ ê¸¸ì´: {len(document)}ì")
            # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
            preview = document.replace('\n', ' ')[:150]
            print(f"    ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {preview}...")
    else:
        print("ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    print("\n" + "="*60)
    print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„")
    print("="*60)

    categories = {}
    for metadata in results['metadatas']:
        category = metadata.get('category', 'Unknown')
        categories[category] = categories.get(category, 0) + 1

    for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
        print(f"  {category}: {count}ê°œ")

    # ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n" + "="*60)
    print("ğŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*60)

    test_queries = [
        "ì•Œë¦¼ì´ ì•ˆì™€ìš”",
        "ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°",
    ]

    for query in test_queries:
        print(f"\nğŸ“Œ ì¿¼ë¦¬: '{query}'")
        results = vectorstore.similarity_search_with_score(query, k=3)

        for i, (doc, score) in enumerate(results, 1):
            print(f"  [{i}] ìœ ì‚¬ë„: {score:.4f}")
            print(f"      ì œëª©: {doc.metadata['title']}")
            print(f"      ì¹´í…Œê³ ë¦¬: {doc.metadata['category']}")

    print("\n" + "="*60)
    print("âœ… í™•ì¸ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    inspect_vectorstore()
